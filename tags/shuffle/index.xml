<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Shuffle on 迁移自(blog.csdn.net/xiaobin_HLJ80)</title>
    <link>https://tdtc-hrb.github.io/csdn/tags/shuffle/</link>
    <description>Recent content in Shuffle on 迁移自(blog.csdn.net/xiaobin_HLJ80)</description>
    <generator>Hugo</generator>
    <language>zh-CN</language>
    <lastBuildDate>Tue, 14 Apr 2020 03:08:08 +0800</lastBuildDate>
    <atom:link href="https://tdtc-hrb.github.io/csdn/tags/shuffle/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>hadoop名词解释</title>
      <link>https://tdtc-hrb.github.io/csdn/post/ops_hadoop_abbr1/</link>
      <pubDate>Tue, 14 Apr 2020 03:08:08 +0800</pubDate>
      <guid>https://tdtc-hrb.github.io/csdn/post/ops_hadoop_abbr1/</guid>
      <description>&lt;h1 id=&#34;qjm-and-shuffle&#34;&gt;QJM and shuffle&lt;/h1&gt;&#xA;&lt;h1 id=&#34;1-qjm&#34;&gt;1. QJM&lt;/h1&gt;&#xA;&lt;h2 id=&#34;11-背景&#34;&gt;1.1 背景&lt;/h2&gt;&#xA;&lt;p&gt;自从hadoop2版本开始，社区引入了NameNode高可用方案。NameNode主从节点间需要同步操作日志来达到主从节点元数据一致。最初业界均通过NFS来实现日志同步，大家之所以选择NFS，一方面因为可以很方便地实现数据共享，另外一方面因为NFS已经发展20多年，已经相对稳定成熟。&lt;/p&gt;&#xA;&lt;p&gt;虽然如此，NFS也有缺点不能满足HDFS的在线存储业务：网络单点及其存储节点单点。业界提供了数据共享的一些高可用解决方案，但均不能很好地满足目前HDFS的应用场景。&lt;/p&gt;&#xA;&lt;table&gt;&#xA;  &lt;thead&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;th&gt;方案&lt;/th&gt;&#xA;          &lt;th&gt;网络单点&lt;/th&gt;&#xA;          &lt;th&gt;存储单点&lt;/th&gt;&#xA;          &lt;th&gt;备注&lt;/th&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/thead&gt;&#xA;  &lt;tbody&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;Mysql&lt;/td&gt;&#xA;          &lt;td&gt;HA&lt;/td&gt;&#xA;          &lt;td&gt;无&lt;/td&gt;&#xA;          &lt;td&gt;无&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;Drbd+heartbeat+NFS&lt;/td&gt;&#xA;          &lt;td&gt;无&lt;/td&gt;&#xA;          &lt;td&gt;无&lt;/td&gt;&#xA;          &lt;td&gt;脑裂；数据有丢失风险&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;Keepalive+NFS&lt;/td&gt;&#xA;          &lt;td&gt;无&lt;/td&gt;&#xA;          &lt;td&gt;有&lt;/td&gt;&#xA;          &lt;td&gt;数据有丢失风险&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/tbody&gt;&#xA;&lt;/table&gt;&#xA;&lt;p&gt;为了满足共享日志的高可用性，社区引入QJM。QJM由cloudera开发，实现了读写高可用性，使HDFS达到真正的高可用性成为可能。&lt;/p&gt;&#xA;&lt;h2 id=&#34;12-术语和定义&#34;&gt;1.2 术语和定义&lt;/h2&gt;&#xA;&lt;table&gt;&#xA;  &lt;thead&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;th&gt;术语和定义&lt;/th&gt;&#xA;          &lt;th&gt;解释&lt;/th&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/thead&gt;&#xA;  &lt;tbody&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;Epoch&lt;/td&gt;&#xA;          &lt;td&gt;由主节点在启动及其切换为主的时候分配，每次操作JN节点均会检查该值,类似zookeeper中的zxid，此时主NameNode类似zookeeper中的leader，JN节点类似ZK中的Follower&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;JournalNode&lt;/td&gt;&#xA;          &lt;td&gt;QJM存储段进程，提供日志读写，存储，修复等服务&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;QJM&lt;/td&gt;&#xA;          &lt;td&gt;Qurom Journal Manager&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;startLogSegment&lt;/td&gt;&#xA;          &lt;td&gt;开始一个新的日志段,该日志段状态为接收写入日志的状态&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;finalizeLogSegment&lt;/td&gt;&#xA;          &lt;td&gt;将文件由正在写入日志的状态转化为不接收写日志的状态&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;recoverUnfinalizedSegments&lt;/td&gt;&#xA;          &lt;td&gt;主从切换等情况下，恢复没有转换为finalized状态的日志&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;journalId&lt;/td&gt;&#xA;          &lt;td&gt;日志ID，由配置指定，如qjournal://g42:8485;g35:8485;uhp9:8485/geminifs，则其中的geminifs即为journalId&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/tbody&gt;&#xA;&lt;/table&gt;&#xA;&lt;h1 id=&#34;2shuffle&#34;&gt;2. shuffle&lt;/h1&gt;&#xA;&lt;p&gt;作者：Lijie Xu&#xA;链接：https://www.zhihu.com/question/27643595/answer/127473409&#xA;来源：知乎&#xA;著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;从逻辑角度来讲，Shuffle 过程就是一个 GroupByKey 的过程，两者没有本质区别。&#xA;只是 MapReduce 为了方便 GroupBy 存在于不同 partition 中的 key/value records，就提前对 key 进行排序。Spark 认为很多应用不需要对 key 排序，就默认没有在 GroupBy 的过程中对 key 排序。&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
